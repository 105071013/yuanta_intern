---
title: "<center>Statistical Learning HW5<center>"
author: "<p align='right'>105071013 </p>>"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**1.**
```{r, echo=FALSE}
#1
#generate train and test data independently
#training data
library(MASS)
set.seed(100)
n_train <- 50
train_x <- matrix(runif(n_train, -2, 2), nrow = n_train)
train_y <- 2 + 0.75*sin(train_x) - 0.75*cos(train_x) + rnorm(n_train, 0, 0.2)
#testing set
set.seed(2)
n_test <- 50
test_x <- matrix(runif(n_test, -2, 2), nrow = n_test)
test_y <- 2 + 0.75*sin(test_x) - 0.75*cos(test_x) + rnorm(n_test, 0, 0.2)
```

**2.**

**(a)**
```{r, echo=FALSE}
#2
#fit a linear curve
train_x2 <- cbind(rep(1, times = 50), train_x)
test_x2 <- cbind(rep(1, times = 50), test_x)
beta <- solve(t(train_x2)%*%train_x2)%*%t(train_x2)%*%train_y
cat('beta0 and beta1:', beta)
```

**(b)**
```{r, echo=FALSE}
#calculate MSE
MSE_train <- (1/50)*sum((train_y - train_x2 %*% beta)^2)
MSE_test <- (1/50)*sum((test_y - test_x2 %*% beta)^2)
cat('MSE based on training data:', MSE_train)
cat('MSE based on testing data:', MSE_test)
```

**3.**

**(a)**
```{r, echo=FALSE}
#3
#add some quardratic term
train_x3 <- cbind(rep(1, times = 50), train_x, train_x^2, train_x^3)
test_x3 <- cbind(rep(1, times = 50), test_x, test_x^2, test_x^3)
beta_poly <- solve(t(train_x3)%*%train_x3)%*%t(train_x3)%*%train_y
cat('polynomial curve beta:', beta_poly)
```

**(b)**
```{r, echo=FALSE}
#calculate MSE
MSE_poly_train <- (1/50)*sum((train_y - train_x3 %*% beta_poly)^2)
MSE_poly_test <- (1/50)*sum((test_y - test_x3 %*% beta_poly)^2)
cat('MSE based on training data:', MSE_poly_train)
cat('MSE based on testing data:', MSE_poly_test)
```

**4.**

**(a)**
```{r, echo=FALSE}
#4
#fit a spline curve
#k = 3, m = 12
nknots <- 12
mat.tpb <- function(x, nknots){
  n <- length(x)
  knots <- seq(-2, 2, len = nknots)
  zb <- cbind(1, x, x^2, x^3)
  zt <- matrix(NA, nrow = n, ncol = nknots)
  for(i in 1:nknots){
    zt[, i] <- ifelse(x > knots[i], (x - knots[i])^3, 0)
  }
  cbind(zb, zt)
}
train_x4 <- mat.tpb(train_x, nknots)
test_x4 <- mat.tpb(test_x, nknots)
#design matrix is not full rank -> use ginv
beta_spline <- ginv(t(train_x4) %*% train_x4) %*% t(train_x4) %*% train_y 
cat('spline curve beta:', beta_spline)
```

**(b)**
```{r, echo=FALSE}
#calculate MSE
MSE_spline_train <- (1/50)*sum((train_y - train_x4 %*% beta_spline)^2)
MSE_spline_test <- (1/50)*sum((test_y - test_x4 %*% beta_spline)^2)
cat('MSE based on training data:', MSE_spline_train)
cat('MSE based on testing data:', MSE_spline_test)
```

**5.**

**(a)**
```{r, echo=FALSE, fig.height = 5, fig.width = 10, fig.align = "center"}
#5
#a1
#generate -3~3 sample pts
x0 <- seq(-3, 3, len = 1000)
#plot
par(mfrow=c(1,2))
plot(train_x, train_y, xlab = "X", ylab = "Y", main = "figure 1") 
lines(x0, 2 + 0.75*sin(x0) - 0.75*cos(x0), col = 'black', lwd = 2)
lines(x0, cbind(rep(1, times = 1000), x0) %*% beta, col = 'orange', lwd = 2)
lines(x0, cbind(rep(1, times = 1000), x0, x0^2, x0^3) %*% beta_poly, col = 'green', lwd = 2)
lines(x0, mat.tpb(x0, nknots) %*% beta_spline, col = 'blue', lwd = 2)
legend("bottomright", legend = c('True Curve', 'linear', 'poly', 'spline'),
       lty = c(1, 1, 1, 1), col = c('black', 'orange', 'green', 'blue'), cex = 1)
#a2
#set the flexibility to level 1, 2, 3 -> linear, poly, spline
plot(c(2, 4, 16), c(MSE_train, MSE_poly_train, MSE_spline_train), col = 'blue',
     ylim = c(0, 0.18), main = 'figure 2', xlab = 'flexibility', ylab = 'MSE', type = 'b')
lines(c(2, 4, 16), c(MSE_test, MSE_poly_test, MSE_spline_test), col = 'red', type = 'b')
abline(h = 0.04, lty = 3)
legend("bottomright", legend = c('Train MSE', 'Test MSE'), lty = c(1, 1), col = c('blue', 'red'), cex = 1)
```

**(b)**

**6.**
```{r, echo=FALSE}
#6
#calculate each f hat and their expectation
linear_f <- matrix(0, nrow = 50, ncol = 1000)
poly_f <- matrix(0, nrow = 50, ncol = 1000)
spline_f <- matrix(0, nrow = 50, ncol = 1000)

for(i in 1:1000){
  x_b <- runif(n_train, -2, 2)
  y_b <- 2 + 0.75*sin(x_b) - 0.75*cos(x_b) + rnorm(n_train, 0, 0.2)
  model_1 <- lm(y_b ~ x_b)
  linear_f[, i] <- predict(model_1, data.frame(x_b = test_x))
  model_2 <- lm(y_b ~ x_b + I(x_b^2) + I(x_b^3))
  poly_f[, i] <- predict(model_2, data.frame(x_b = test_x))
  z_b <- mat.tpb(x_b, nknots)
  model_3 <- ginv(t(z_b) %*% z_b) %*% t(z_b) %*% y_b
  spline_f[, i] <- mat.tpb(test_x, nknots) %*% model_3
} 
#calculate bias^2 and variance
#bias^2
linear_bias <- mean((2 + 0.75*sin(test_x) - 0.75*cos(test_x) - apply(linear_f, 1, mean))^2)
poly_bias <- mean((2 + 0.75*sin(test_x) - 0.75*cos(test_x) - apply(poly_f, 1, mean))^2)
spline_bias <- mean((2 + 0.75*sin(test_x) - 0.75*cos(test_x) - apply(spline_f, 1, mean))^2)
#variance
linear_variance <- mean((test_x2 %*% beta - apply(linear_f, 1, mean))^2)
poly_variance <- mean((test_x3 %*% beta_poly - apply(poly_f, 1, mean))^2)
spline_variance <- mean((test_x4 %*% beta_spline - apply(spline_f, 1, mean))^2)
all <- data.frame(c(linear_bias, poly_bias, spline_bias), c(linear_variance, poly_variance, spline_variance), 
                  c(MSE_test, MSE_poly_test, MSE_spline_test), row.names = c('Linear', 'Poly', 'Spline'))
colnames(all) <- c('Squared Bias', 'Variance', 'MSE based on testing data')
all
```

```{r, echo=FALSE, fig.height = 5, fig.width = 10, fig.align = "center"}
#plot
plot(c(2, 4, 16), c(MSE_test, MSE_poly_test, MSE_spline_test), col = 'black', type = 'b',
     xlab = 'flexibility', ylab = '', ylim = c(0, 0.2))
lines(c(2, 4, 16), c(linear_bias, poly_bias, spline_bias), col = 'blue', type = 'b')
lines(c(2, 4, 16), c(linear_variance, poly_variance, spline_variance), col = 'red', type = 'b')
abline(h = 0.04, lty = 3)
legend("topright", legend = c('Test MSE', 'Squared Bias', 'Variance'), lty = c(1, 1, 1), col = c('black', 'blue', 'red'), cex = 1)
```

```{r, echo=FALSE}
#diff between testing MSE and bias + variance
diff_linear <- MSE_test - linear_bias - linear_variance
diff_poly <- MSE_poly_test - poly_bias - poly_variance
diff_spline <- MSE_spline_test - spline_bias - spline_variance
diff1 <- data.frame(diff_linear, diff_poly, diff_spline, row.names = '') 
diff1
```

```{r, echo=FALSE}
#the diff did not converge to 0.04 because the test set is too small
#when we have 5000 testing set
set.seed(2)
n_test_new <- 5000
test_x_new <- matrix(runif(n_test_new, -2, 2), nrow = n_test_new)
test_y_new <- 2 + 0.75*sin(test_x_new) - 0.75*cos(test_x_new) + rnorm(n_test_new, 0, 0.2)
#calculate the bias and variance again
linear_f_new <- matrix(0, nrow = n_test_new, ncol = 1000)
poly_f_new <- matrix(0, nrow = n_test_new, ncol = 1000)
spline_f_new <- matrix(0, nrow = n_test_new, ncol = 1000)

for(i in 1:1000){
  x_b <- runif(n_train, -2, 2)
  y_b <- 2 + 0.75*sin(x_b) - 0.75*cos(x_b) + rnorm(n_train, 0, 0.2)
  model_1 <- lm(y_b ~ x_b)
  linear_f_new[, i] <- predict(model_1, data.frame(x_b = test_x_new))
  model_2 <- lm(y_b ~ x_b + I(x_b^2) + I(x_b^3))
  poly_f_new[, i] <- predict(model_2, data.frame(x_b = test_x_new))
  z_b <- mat.tpb(x_b, nknots)
  model_3 <- ginv(t(z_b) %*% z_b) %*% t(z_b) %*% y_b
  spline_f_new[, i] <- mat.tpb(test_x_new, nknots) %*% model_3
} 
#calculate bias^2 and variance
#bias^2
linear_bias_new <- mean((2 + 0.75*sin(test_x_new) - 0.75*cos(test_x_new) - apply(linear_f_new, 1, mean))^2)
poly_bias_new <- mean((2 + 0.75*sin(test_x_new) - 0.75*cos(test_x_new) - apply(poly_f_new, 1, mean))^2)
spline_bias_new <- mean((2 + 0.75*sin(test_x_new) - 0.75*cos(test_x_new) - apply(spline_f_new, 1, mean))^2)
#variance
linear_variance_new <- mean((cbind(rep(1, times = 5000), test_x_new) %*% beta - apply(linear_f_new, 1, mean))^2)
poly_variance_new <- mean((cbind(rep(1, times = 5000), test_x_new, test_x_new^2, test_x_new^3) %*% beta_poly - apply(poly_f_new, 1, mean))^2)
spline_variance_new <- mean((mat.tpb(test_x_new, nknots) %*% beta_spline - apply(spline_f_new, 1, mean))^2)
#new testing MSE
MSE_test_new <- (1/n_test_new)*sum((test_y_new - cbind(rep(1, times = 5000), test_x_new) %*% beta)^2)
MSE_poly_test_new <- (1/n_test_new)*sum((test_y_new - cbind(rep(1, times = 5000), test_x_new, test_x_new^2, test_x_new^3) %*% beta_poly)^2)
MSE_spline_test_new <- (1/n_test_new)*sum((test_y_new - mat.tpb(test_x_new, nknots) %*% beta_spline)^2)
#diff between testing MSE and bias + variance
diff_linear_new <- MSE_test_new - linear_bias_new - linear_variance_new
diff_poly_new <- MSE_poly_test_new - poly_bias_new - poly_variance_new
diff_spline_new <- MSE_spline_test_new - spline_bias_new - spline_variance_new
diff2 <- data.frame(diff_linear_new, diff_poly_new, diff_spline_new, row.names = '') 
diff2
```